# Open Source Workflow Builders for Self-Hosted AI Automation

**Research Date:** January 24, 2026  
**Target Environment:** Mac mini (Apple Silicon)  
**Focus:** Agentic workflows, local LLMs, MCP integration

---

## Executive Summary

After researching the major open-source workflow builders, **Sim Studio** emerges as the best fit for Marb's Mac mini for building agentic AI workflows, with **n8n** as a strong alternative for general automation. Both support Ollama for local LLMs and have excellent self-hosting capabilities.

### Quick Recommendation

| Use Case | Recommended Tool |
|----------|------------------|
| **AI Agent Workflows** | Sim Studio |
| **General Automation (400+ integrations)** | n8n |
| **Code-First Workflows** | Windmill |
| **Enterprise Durable Execution** | Temporal |
| **Serverless Step Functions** | Inngest |
| **LLM App Development** | Dify or Langflow |

---

## 1. Sim Studio

### Overview
**GitHub:** [simstudioai/sim](https://github.com/simstudioai/sim)  
**Website:** [sim.ai](https://sim.ai)  
**License:** Apache 2.0  
**Focus:** Visual AI agent workflow builder

Sim is an open-source visual workflow builder specifically designed for AI agent workflows. It features a drag-and-drop canvas for connecting AI models, databases, APIs, and business tools.

### Key Features
- ðŸŽ¨ **Visual Workflow Editor** - Intuitive drag-and-drop canvas
- ðŸ¤– **AI Agent Blocks** - Native support for agent orchestration
- ðŸ”§ **80+ Integrations** - OpenAI, Anthropic, Google, Slack, Gmail, etc.
- ðŸ”Œ **MCP Support** - Native Model Context Protocol integration
- ðŸ¦™ **Ollama Integration** - Run local LLMs without external APIs
- ðŸ¤ **Copilot Assistant** - AI-powered workflow building
- ðŸ“Š **Vector Database Support** - Qdrant, Pinecone integration

### MCP Integration (Native!)
Sim has **first-class MCP support**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Sim Workflow Canvas                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Trigger â”‚â”€â”€â”€â–¶â”‚  Agent  â”‚â”€â”€â”€â–¶â”‚  MCP Tool Block â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                       â”‚                             â”‚
â”‚                       â–¼                             â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚            â”‚  MCP Server Pool â”‚                     â”‚
â”‚            â”‚  - Database MCP  â”‚                     â”‚
â”‚            â”‚  - File System   â”‚                     â”‚
â”‚            â”‚  - Custom APIs   â”‚                     â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Using MCP in Sim:**
1. Navigate to Workspace Settings â†’ Deployed MCPs
2. Click "Add MCP Server"
3. Configure server connection details
4. Tools become available in Agent blocks

### Ollama Integration

**Option 1: Bundled Ollama (Recommended for Mac)**
```bash
# Clone repo
git clone https://github.com/simstudioai/sim.git && cd sim

# Start with Ollama profile (GPU support on Mac)
docker compose -f docker-compose.ollama.yml --profile setup up -d

# Wait for model download, then visit http://localhost:3000
```

**Option 2: External Ollama (Running on Host)**
```bash
# If Ollama is already running on your Mac
OLLAMA_URL=http://host.docker.internal:11434 docker compose -f docker-compose.prod.yml up -d
```

### Installation Guide (Mac mini)

**Prerequisites:**
- Docker Desktop for Mac
- 12GB+ RAM recommended

**Quick Start (NPM - Simplest):**
```bash
npx simstudio
# Opens at http://localhost:3000
```

**Docker Compose (Production):**
```bash
git clone https://github.com/simstudioai/sim.git
cd sim
docker compose -f docker-compose.prod.yml up -d
# Visit http://localhost:3000
```

**Manual Setup (Development):**
```bash
# Prerequisites: Bun, Node.js v20+, PostgreSQL with pgvector
git clone https://github.com/simstudioai/sim.git
cd sim
bun install

# Start PostgreSQL with pgvector
docker run --name simstudio-db -e POSTGRES_PASSWORD=changeme \
  -e POSTGRES_DB=simstudio -p 5432:5432 -d pgvector/pgvector:pg17

# Configure environment
cp apps/sim/.env.example apps/sim/.env
cp packages/db/.env.example packages/db/.env
# Edit both to set DATABASE_URL

# Run migrations
cd packages/db && bunx drizzle-kit migrate --config=./drizzle.config.ts

# Start dev servers
bun run dev:full
```

### Tech Stack
- **Framework:** Next.js (App Router)
- **Runtime:** Bun
- **Database:** PostgreSQL + pgvector
- **Auth:** Better Auth
- **UI:** Shadcn + Tailwind CSS
- **Flow Editor:** ReactFlow
- **Realtime:** Socket.io

---

## 2. n8n

### Overview
**GitHub:** [n8n-io/n8n](https://github.com/n8n-io/n8n) (162k+ stars)  
**Website:** [n8n.io](https://n8n.io)  
**License:** Fair-code (Sustainable Use License)  
**Focus:** General workflow automation with AI capabilities

n8n is the most popular open-source workflow automation platform. It combines visual building with custom code support and has native AI capabilities built on LangChain.

### Key Features
- ðŸ”— **400+ Integrations** - Largest integration library
- ðŸ **Code When Needed** - JavaScript/Python support
- ðŸ¤– **AI-Native** - LangChain-based AI workflows
- ðŸ  **Self-Host Friendly** - Full control over data
- ðŸ¢ **Enterprise Ready** - SSO, permissions, air-gapped

### AI Capabilities (LangChain-Based)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  n8n AI Workflow                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Trigger  â”‚â”€â”€â–¶â”‚AI Agent â”‚â”€â”€â–¶â”‚ Tool Nodes           â”‚ â”‚
â”‚  â”‚(Chat/API)â”‚   â”‚(LangChain)  â”‚ - Calculator         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ - Web Search         â”‚ â”‚
â”‚                      â”‚        â”‚ - Code Execution     â”‚ â”‚
â”‚                      â–¼        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚              â”‚ LLM Node    â”‚                           â”‚
â”‚              â”‚ - OpenAI    â”‚                           â”‚
â”‚              â”‚ - Ollama âœ“  â”‚                           â”‚
â”‚              â”‚ - Anthropic â”‚                           â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Ollama Integration
n8n has a dedicated **Ollama Model node** for local LLM support:

1. Install Ollama on your Mac: `brew install ollama`
2. Pull a model: `ollama pull llama3.2`
3. In n8n, add "Ollama Model" sub-node
4. Configure base URL: `http://host.docker.internal:11434`

**Note:** The Ollama node works with Basic LLM Chain, not the AI Agent node (lacks tools support).

### Self-Hosted AI Starter Kit ðŸŒŸ

n8n provides a complete local AI stack:

```bash
git clone https://github.com/n8n-io/self-hosted-ai-starter-kit.git
cd self-hosted-ai-starter-kit
cp .env.example .env

# For Mac (Apple Silicon) - run Ollama separately
docker compose up

# Set OLLAMA_HOST=host.docker.internal:11434 in .env
```

**What's Included:**
- âœ… n8n (workflow automation)
- âœ… Ollama (local LLMs)
- âœ… Qdrant (vector database)
- âœ… PostgreSQL (data storage)

### Installation Guide (Mac mini)

**Quick Start (npx):**
```bash
npx n8n
# Opens at http://localhost:5678
```

**Docker (Recommended):**
```bash
docker volume create n8n_data
docker run -it --rm --name n8n -p 5678:5678 \
  -v n8n_data:/home/node/.n8n \
  docker.n8n.io/n8nio/n8n
```

---

## 3. Windmill

### Overview
**GitHub:** [windmill-labs/windmill](https://github.com/windmill-labs/windmill)  
**Website:** [windmill.dev](https://windmill.dev)  
**License:** AGPLv3 (Community) / Commercial  
**Focus:** Developer platform for scripts, workflows, and UIs

Windmill is the **fastest self-hostable workflow engine** (13x faster than Airflow). It's designed for developers who want to write code but need workflow orchestration.

### Key Features
- âš¡ **Fastest Engine** - 13x faster than Airflow
- ðŸ’» **Multi-Language** - Python, TypeScript, Go, PHP, Bash, SQL
- ðŸ”’ **Secure Sandboxing** - nsjail for production-grade isolation
- ðŸŽ¨ **Auto-Generated UIs** - Scripts become UIs automatically
- ðŸ“Š **Low-Code App Builder** - Build internal tools

### Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Windmill Architecture               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Frontend â”‚    â”‚ API      â”‚    â”‚ Workers          â”‚ â”‚
â”‚  â”‚ (Svelte) â”‚â—€â”€â”€â–¶â”‚ (Rust)   â”‚â—€â”€â”€â–¶â”‚ (Pull from queue)â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                       â”‚                    â”‚           â”‚
â”‚                       â–¼                    â–¼           â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚              â”‚ PostgreSQL  â”‚    â”‚ nsjail Sandbox   â”‚  â”‚
â”‚              â”‚ (Jobs/State)â”‚    â”‚ - Deno (JS/TS)   â”‚  â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ - Python3        â”‚  â”‚
â”‚                                 â”‚ - Go/Bash        â”‚  â”‚
â”‚                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Installation (Mac mini)

```bash
# Download compose files
curl https://raw.githubusercontent.com/windmill-labs/windmill/main/docker-compose.yml -o docker-compose.yml
curl https://raw.githubusercontent.com/windmill-labs/windmill/main/Caddyfile -o Caddyfile
curl https://raw.githubusercontent.com/windmill-labs/windmill/main/.env -o .env

docker compose up -d
# Visit http://localhost
# Login: admin@windmill.dev / changeme
```

### When to Use Windmill
- You prefer writing code over visual builders
- You need the fastest execution times
- You want auto-generated UIs from scripts
- You're building internal developer tools

---

## 4. Temporal

### Overview
**GitHub:** [temporalio/temporal](https://github.com/temporalio/temporal)  
**Website:** [temporal.io](https://temporal.io)  
**License:** MIT  
**Focus:** Durable execution platform

Temporal is a production-grade durable execution platform. It originated as a fork of Uber's Cadence and is designed for building scalable applications that automatically handle failures.

### Key Features
- ðŸ”„ **Durable Execution** - Survives failures and restarts
- â±ï¸ **Long-Running Workflows** - Days, weeks, months
- ðŸ” **Automatic Retries** - Built-in failure handling
- ðŸ“ˆ **Highly Scalable** - Battle-tested at Uber scale
- ðŸ§ª **Testable** - First-class testing support

### Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Temporal Architecture                â”‚
â”‚                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Your App     â”‚    â”‚ Temporal Server          â”‚   â”‚
â”‚  â”‚ (Worker)     â”‚â—€â”€â”€â–¶â”‚ - History Service        â”‚   â”‚
â”‚  â”‚ - Workflows  â”‚    â”‚ - Matching Service       â”‚   â”‚
â”‚  â”‚ - Activities â”‚    â”‚ - Frontend Service       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                       â”‚
â”‚                              â–¼                       â”‚
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚                      â”‚ PostgreSQL/  â”‚               â”‚
â”‚                      â”‚ Cassandra    â”‚               â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Installation (Mac mini)

```bash
# Install CLI
brew install temporal

# Start dev server
temporal server start-dev

# Web UI at http://localhost:8233
```

### When to Use Temporal
- Building mission-critical workflows
- Need durable execution guarantees
- Complex multi-service orchestration
- You have engineering resources for code-first approach

---

## 5. Inngest

### Overview
**GitHub:** [inngest/inngest](https://github.com/inngest/inngest)  
**Website:** [inngest.com](https://inngest.com)  
**License:** SSPL (Server) / Apache 2.0 (SDKs)  
**Focus:** Durable functions for serverless

Inngest provides durable step functions that replace queues, state management, and scheduling. It's designed for developers building reliable background jobs.

### Key Features
- ðŸ”§ **Durable Functions** - Auto-retry, state persistence
- ðŸŽ¯ **Event-Driven** - Trigger by events, cron, webhooks
- ðŸš¦ **Flow Control** - Concurrency, throttling, rate limiting
- ðŸƒ **Step Functions** - Break work into reliable steps
- â˜ï¸ **Serverless-First** - Deploy anywhere

### How It Works
```typescript
// Inngest durable function example
export default inngest.createFunction(
  {
    id: "process-order",
    concurrency: { key: "event.data.userId", limit: 5 }
  },
  { event: "order/created" },
  async ({ event, step }) => {
    // Each step is individually retried on failure
    const validated = await step.run("validate", async () => {
      return validateOrder(event.data);
    });
    
    await step.run("charge", async () => {
      return chargeCard(validated);
    });
    
    await step.run("fulfill", async () => {
      return fulfillOrder(validated);
    });
  }
);
```

### Installation (Mac mini)

```bash
# Run dev server
npx inngest-cli@latest dev

# Dashboard at http://localhost:8288
```

### When to Use Inngest
- Serverless background jobs
- Event-driven architectures
- Need flow control (throttling, concurrency)
- TypeScript/JavaScript projects

---

## 6. Additional Alternatives

### Langflow
**GitHub:** [langflow-ai/langflow](https://github.com/langflow-ai/langflow)  
**Focus:** LangChain visual builder

- âœ… **MCP Support** - Deploy flows as MCP servers
- âœ… Visual builder for LangChain
- âœ… Desktop app available
- âœ… Python-based

```bash
uv pip install langflow -U
uv run langflow run
# http://127.0.0.1:7860
```

### Dify
**GitHub:** [langgenius/dify](https://github.com/langgenius/dify)  
**Focus:** LLM application development platform

- âœ… Agentic workflow builder
- âœ… RAG pipeline support
- âœ… 50+ built-in tools
- âœ… LLMOps features

```bash
git clone https://github.com/langgenius/dify.git
cd dify/docker
cp .env.example .env
docker compose up -d
# http://localhost/install
```

---

## Comparison Table

| Feature | Sim | n8n | Windmill | Temporal | Inngest | Langflow | Dify |
|---------|-----|-----|----------|----------|---------|----------|------|
| **Visual Builder** | âœ… Excellent | âœ… Excellent | âœ… Good | âŒ Code-only | âŒ Code-only | âœ… Excellent | âœ… Excellent |
| **MCP Support** | âœ… Native | âŒ | âŒ | âŒ | âŒ | âœ… Native | âŒ |
| **Ollama Support** | âœ… Native | âœ… Node | âšª Via API | âšª Via API | âšª Via API | âœ… | âœ… |
| **Integrations** | 80+ | 400+ | 300+ | SDK-based | SDK-based | LangChain | 50+ tools |
| **AI-First** | âœ… | âœ… (LangChain) | âšª | âŒ | âŒ | âœ… | âœ… |
| **Code Support** | TypeScript | JS/Python | Multi-lang | Multi-lang | TS/Python | Python | Python |
| **Self-Host Ease** | ðŸŸ¢ Easy | ðŸŸ¢ Easy | ðŸŸ¢ Easy | ðŸŸ¡ Medium | ðŸŸ¢ Easy | ðŸŸ¢ Easy | ðŸŸ¢ Easy |
| **Mac Optimized** | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… |
| **License** | Apache 2.0 | Fair-code | AGPLv3 | MIT | SSPL | MIT | Apache 2.0 |
| **Community** | Growing | Large | Medium | Large | Growing | Large | Very Large |

---

## Workflow Patterns

### Common Trigger Types
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Trigger Types                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ðŸ“¨ Webhook      â†’ HTTP POST to endpoint        â”‚
â”‚  â° Cron/Schedule â†’ "0 9 * * *" (9am daily)     â”‚
â”‚  ðŸ’¬ Chat         â†’ User message in chat UI      â”‚
â”‚  ðŸ“§ Email        â†’ Incoming email trigger       â”‚
â”‚  ðŸ”” Event        â†’ Event bus message            â”‚
â”‚  ðŸ“ File         â†’ File system change           â”‚
â”‚  ðŸ”— API          â†’ REST API call                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Error Handling Patterns
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Error Handling Strategies                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  1. RETRY WITH BACKOFF                                  â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â” fail â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”              â”‚
â”‚     â”‚Step â”‚â”€â”€â”€â”€â”€â–¶â”‚Wait 2^n â”‚â”€â”€â”€â”€â–¶â”‚Retryâ”‚              â”‚
â”‚     â””â”€â”€â”€â”€â”€â”˜      â”‚ seconds â”‚     â””â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                                                         â”‚
â”‚  2. FALLBACK PATH                                       â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â” fail â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚     â”‚Step â”‚â”€â”€â”€â”€â”€â–¶â”‚Fallback Step â”‚                     â”‚
â”‚     â””â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                                                         â”‚
â”‚  3. DEAD LETTER QUEUE                                   â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â” fail â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚     â”‚Step â”‚â”€â”€â”€â”€â”€â–¶â”‚DLQ/Alertâ”‚                          â”‚
â”‚     â””â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                                                         â”‚
â”‚  4. COMPENSATION (Saga Pattern)                         â”‚
â”‚     â”Œâ”€â”€â”€â”€â” fail â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚     â”‚Stepâ”‚â”€â”€â”€â”€â”€â–¶â”‚Undo Prev â”‚                          â”‚
â”‚     â””â”€â”€â”€â”€â”˜      â”‚  Steps   â”‚                          â”‚
â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Agent Workflow Pattern
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Agentic Workflow Pattern                   â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Input   â”‚â”€â”€â”€â–¶â”‚            AI Agent                  â”‚   â”‚
â”‚  â”‚ (Query) â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚         Tool Selection         â”‚  â”‚   â”‚
â”‚                 â”‚  â”‚  "I need to search the web"    â”‚  â”‚   â”‚
â”‚                 â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚                 â”‚              â”‚                        â”‚   â”‚
â”‚                 â”‚              â–¼                        â”‚   â”‚
â”‚                 â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚                 â”‚  â”‚       Execute Tool             â”‚  â”‚   â”‚
â”‚                 â”‚  â”‚  - web_search("query")         â”‚  â”‚   â”‚
â”‚                 â”‚  â”‚  - read_file("/path")          â”‚  â”‚   â”‚
â”‚                 â”‚  â”‚  - mcp_tool("action")          â”‚  â”‚   â”‚
â”‚                 â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚                 â”‚              â”‚                        â”‚   â”‚
â”‚                 â”‚              â–¼                        â”‚   â”‚
â”‚                 â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚                 â”‚  â”‚      Process Results           â”‚  â”‚   â”‚
â”‚                 â”‚  â”‚  Loop until task complete      â”‚  â”‚   â”‚
â”‚                 â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                              â”‚
â”‚                              â–¼                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    Final Output                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Recommended Stack for Mac mini

### Primary Stack: Sim + Ollama + Qdrant

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Recommended Local AI Stack                     â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    Sim Studio                        â”‚   â”‚
â”‚  â”‚        Visual AI Workflow Builder (Port 3000)        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â”‚                                  â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚           â–¼              â–¼              â–¼                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚   Ollama     â”‚ â”‚  Qdrant    â”‚ â”‚   PostgreSQL   â”‚       â”‚
â”‚  â”‚  (Port 11434)â”‚ â”‚(Port 6333) â”‚ â”‚  (Port 5432)   â”‚       â”‚
â”‚  â”‚              â”‚ â”‚            â”‚ â”‚                â”‚       â”‚
â”‚  â”‚ - llama3.2   â”‚ â”‚ - Vector   â”‚ â”‚ - Workflow     â”‚       â”‚
â”‚  â”‚ - mistral    â”‚ â”‚   Search   â”‚ â”‚   State        â”‚       â”‚
â”‚  â”‚ - gemma2     â”‚ â”‚ - RAG      â”‚ â”‚ - pgvector     â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                   MCP Servers                        â”‚   â”‚
â”‚  â”‚  - File System MCP (local files)                     â”‚   â”‚
â”‚  â”‚  - Browser MCP (web automation)                      â”‚   â”‚
â”‚  â”‚  - Database MCP (query databases)                    â”‚   â”‚
â”‚  â”‚  - Custom MCPs (your tools)                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Setup Script

```bash
#!/bin/bash
# setup-local-ai-stack.sh

# 1. Install Ollama (runs natively on Mac for best performance)
brew install ollama
ollama serve &

# 2. Pull recommended models
ollama pull llama3.2
ollama pull mistral
ollama pull nomic-embed-text  # For embeddings

# 3. Clone and start Sim Studio
git clone https://github.com/simstudioai/sim.git
cd sim

# 4. Start with external Ollama
OLLAMA_URL=http://host.docker.internal:11434 \
docker compose -f docker-compose.prod.yml up -d

echo "âœ… Stack ready!"
echo "   Sim Studio: http://localhost:3000"
echo "   Ollama API: http://localhost:11434"
```

### Alternative: n8n AI Starter Kit

If you need more general automation beyond AI:

```bash
git clone https://github.com/n8n-io/self-hosted-ai-starter-kit.git
cd self-hosted-ai-starter-kit
cp .env.example .env

# Edit .env: Set OLLAMA_HOST=host.docker.internal:11434

# Install Ollama separately for Mac
brew install ollama
ollama serve &
ollama pull llama3.2

# Start n8n stack
docker compose up

# n8n: http://localhost:5678
```

---

## Resource Requirements

### Mac mini Specifications

| Component | Minimum | Recommended |
|-----------|---------|-------------|
| **RAM** | 8GB | 16GB+ |
| **Storage** | 50GB free | 100GB+ SSD |
| **CPU** | M1 | M1 Pro/Max or M2+ |
| **Docker** | Docker Desktop | Docker Desktop |

### Per-Tool Memory Usage

| Tool | Idle RAM | Active RAM |
|------|----------|------------|
| Sim Studio | ~500MB | 1-2GB |
| n8n | ~300MB | 500MB-1GB |
| Ollama (7B model) | ~5GB | 5-8GB |
| Ollama (13B model) | ~10GB | 10-14GB |
| Qdrant | ~200MB | 500MB-2GB |
| PostgreSQL | ~100MB | 200-500MB |

**Recommendation:** With 16GB RAM, you can comfortably run:
- Sim or n8n
- Ollama with 7B-8B models
- Qdrant for vector storage
- PostgreSQL for data

---

## Conclusion

### For Marb's Mac mini, I recommend:

1. **Primary: Sim Studio** - Best for AI agent workflows with native MCP support
2. **Ollama** - Run locally for best Mac performance (not in Docker)
3. **Qdrant** - Vector database for RAG workflows
4. **PostgreSQL with pgvector** - Included with Sim

### Why Sim over n8n for AI workflows?

| Aspect | Sim | n8n |
|--------|-----|-----|
| AI-First Design | âœ… Built for agents | âšª AI is an add-on |
| MCP Integration | âœ… Native support | âŒ Not available |
| Ollama Integration | âœ… First-class | âšª Via sub-node |
| Visual Agent Building | âœ… Excellent | âšª Good |
| General Integrations | âšª 80+ | âœ… 400+ |

**If you need 400+ integrations** for non-AI automation, use **n8n** alongside Sim.

---

## Quick Reference Commands

```bash
# Start Sim with local Ollama
OLLAMA_URL=http://host.docker.internal:11434 \
docker compose -f docker-compose.prod.yml up -d

# Pull new Ollama model
ollama pull codellama:7b

# Check Sim logs
docker compose logs -f sim

# Stop everything
docker compose down

# Backup Sim database
docker exec simstudio-db pg_dump -U postgres simstudio > backup.sql
```

---

*Research compiled by Clawdbot â€¢ January 2026*
