# UltraRAG v3 Evaluation

**Research Date:** January 28, 2026  
**Researcher:** Claw (subagent)  
**Purpose:** Evaluate UltraRAG v3 for potential adoption to enhance Claw's memory/recall capabilities

---

## Executive Summary

**UltraRAG v3** is a production-ready, MCP-native RAG framework released January 23, 2026 by Tsinghua University (THUNLP), Northeastern University (NEUIR), OpenBMB, and AI9stars. With 4.5k GitHub stars and active development, it represents the state-of-the-art in RAG orchestration.

**Recommendation: ğŸŸ¡ DEFER â€” Not a drop-in upgrade for our use case**

UltraRAG is impressive but solves a different problem. It's designed for document Q&A systems and research prototyping, not for personal memory/recall in an autonomous agent. Our current file-based memory with local embeddings (embeddinggemma-300M) is simpler and better suited for our needs.

---

## 1. What is UltraRAG v3?

### Overview
- **Type:** Low-code RAG development framework with visual IDE
- **Release:** v3.0 released January 23, 2026 (5 days ago)
- **Stars:** 4.5k on GitHub
- **Repository:** https://github.com/OpenBMB/UltraRAG

### Who Made It
Joint development by prestigious Chinese AI research institutions:
- **THUNLP** â€” Tsinghua University NLP Lab
- **NEUIR** â€” Northeastern University Information Retrieval Lab
- **OpenBMB** â€” Open-source foundation (created CPM models)
- **AI9stars** â€” Research collaboration

### What's New in v3
1. **White-Box Transparency:** Every reasoning step is visible â€” no more "black box" debugging
2. **Visual Pipeline Builder:** Canvas + YAML dual-mode construction with real-time sync
3. **AI Development Assistant:** Natural language interface for pipeline generation and prompt optimization
4. **One-Click Demo Generation:** Instantly convert pipeline logic into interactive web UI
5. **Show Thinking Panel:** Pixel-level visualization of loops, branches, and tool invocations

---

## 2. What Makes It "MCP-Native"?

### Model Context Protocol (MCP) Architecture
UltraRAG is the **first** RAG framework built on [Model Context Protocol](https://modelcontextprotocol.io/) â€” Anthropic's open standard for connecting AI apps to external systems.

#### How MCP Integration Works:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    UltraRAG Architecture                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  MCP Client (Orchestrator)                                  â”‚
â”‚  â”œâ”€â”€ YAML workflow definitions                              â”‚
â”‚  â”œâ”€â”€ Conditional branching & loops                          â”‚
â”‚  â””â”€â”€ Pipeline execution control                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  MCP Servers (Atomic Functions)                             â”‚
â”‚  â”œâ”€â”€ Retriever Server â†’ Vector search, BM25, hybrid         â”‚
â”‚  â”œâ”€â”€ Generation Server â†’ LLM inference                      â”‚
â”‚  â”œâ”€â”€ Reranker Server â†’ Cross-encoder reranking              â”‚
â”‚  â”œâ”€â”€ Chunker Server â†’ Document processing                   â”‚
â”‚  â””â”€â”€ Custom Servers â†’ Register any function as MCP tool     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Key MCP Benefits:
- **Modular:** Each RAG component is an independent MCP server
- **Composable:** Mix and match components via YAML configuration
- **Extensible:** Add new features by registering function-level Tools
- **Standard Protocol:** Compatible with any MCP-supporting client

---

## 3. Comparison: UltraRAG v3 vs. Our Current Memory System

| Aspect | Our System | UltraRAG v3 |
|--------|------------|-------------|
| **Architecture** | File-based + local embeddings | MCP servers + vector DB |
| **Storage** | Markdown files in `memory/` | Milvus vector database |
| **Embeddings** | embeddinggemma-300M (local) | Configurable (OpenAI, local) |
| **Search** | memory_search tool | Hybrid retrieval (vector + BM25) |
| **Complexity** | Simple, zero dependencies | Requires Milvus, LLM server |
| **Use Case** | Personal memory/recall | Document Q&A, research |
| **Control** | Direct file editing | Pipeline-based workflows |
| **Transparency** | Full (it's just files) | Good (Show Thinking panel) |
| **Setup Time** | Already working | Hours of configuration |

### What UltraRAG Does Better:
- âœ… Complex multi-step retrieval with reranking
- âœ… Visual debugging of retrieval pipelines
- âœ… Research benchmarking and evaluation
- âœ… Multi-user document Q&A systems
- âœ… DeepResearch-style long-form report generation

### What Our System Does Better:
- âœ… Zero infrastructure (no Milvus, no servers)
- âœ… Human-readable storage (can edit memories manually)
- âœ… Faster for small memory corpus
- âœ… No network dependencies
- âœ… Simpler mental model (files, not pipelines)

---

## 4. Installation & Setup Requirements

### System Requirements
- Python 3.10+
- 8GB+ RAM (16GB recommended)
- GPU recommended for local models
- Docker (optional, for container deployment)

### Core Dependencies
```bash
# Using uv (recommended)
git clone https://github.com/OpenBMB/UltraRAG.git
cd UltraRAG
uv sync --all-extras

# Verify
ultrarag run examples/sayhello.yaml
```

### Full Production Setup Requires:
1. **Vector Database:** Milvus (Docker container)
2. **LLM Backend:** OpenAI API, local Ollama, or vLLM server
3. **Retriever Model:** Embedding model (e.g., BGE, Jina, OpenAI)
4. **Reranker (optional):** Cross-encoder model

### Docker Quick Start
```bash
docker pull hdxin2002/ultrarag:v0.3.0
docker run -it --gpus all -p 5050:5050 hdxin2002/ultrarag:v0.3.0
# Access at http://localhost:5050
```

---

## 5. Could It Upgrade Claw's Memory/Recall?

### Analysis

**Short answer: Not really.**

UltraRAG solves a different problem. It's designed for:
- Building document Q&A chatbots
- Research experiments on RAG algorithms
- Complex retrieval pipelines with reranking
- Multi-user production systems

Claw's memory needs are:
- Personal episodic memory (what happened on date X)
- Quick recall of past decisions, lessons, context
- Low-latency search across small corpus (~50 daily files)
- Human-editable format

### Specific Issues:

1. **Overkill Infrastructure:** Milvus + MCP servers for ~50 markdown files is excessive

2. **Loss of Editability:** Our current system lets us manually edit MEMORY.md. UltraRAG abstracts storage into vector DB.

3. **Wrong Granularity:** UltraRAG chunks documents for Q&A. Our memories are already structured as daily entries.

4. **Startup Overhead:** UltraRAG requires server processes. Our memory_search is instant.

---

## 6. Alternative MCP-RAG Options

For completeness, I evaluated other MCP-native RAG approaches:

### supernova-mcp-rag
- **Type:** POC for Cursor integration
- **Status:** Demo project, not production-ready
- **Verdict:** Too minimal

### ragit
- **Type:** Lightweight RAG toolkit for Python
- **Status:** Simple but not MCP-native (just tagged)
- **Verdict:** Similar to what we already have

---

## 7. Recommendations

### âŒ Do NOT Adopt UltraRAG v3 For:
- Replacing our file-based memory system
- Simple recall tasks
- Personal agent memory

### âœ… Consider UltraRAG v3 For:
- **Future project:** Building document Q&A for clients
- **Research:** Testing advanced RAG techniques
- **DeepResearch:** If we want multi-step report generation

### ğŸ”§ Potential Improvements to Current System:
Instead of UltraRAG, consider:

1. **Hybrid Search:** Add BM25 keyword matching alongside vector search
2. **Reranking:** Add cross-encoder reranking for better precision
3. **Memory Consolidation:** Periodic agent that summarizes old daily files into MEMORY.md
4. **Graph Memory:** Add entity relationships (who, what, when connections)

These can be done incrementally without replacing the entire system.

---

## 8. Conclusion

UltraRAG v3 is an impressive framework â€” genuinely cutting-edge for RAG research and production document Q&A systems. However, it's not the right tool for enhancing Claw's personal memory capabilities.

Our current approach (file-based memory + local embeddings via embeddinggemma-300M) is:
- Simpler
- More appropriate for our corpus size
- More transparent and editable
- Already working well

**If we need better recall, we should enhance our existing system** with hybrid search or reranking, not replace it with a heavyweight framework designed for different use cases.

---

## References

- [UltraRAG GitHub](https://github.com/OpenBMB/UltraRAG)
- [UltraRAG v3 Release Blog](https://github.com/OpenBMB/UltraRAG/blob/page/project/blog/en/ultrarag3_0.md)
- [Model Context Protocol](https://modelcontextprotocol.io/)
- [UltraRAG Documentation](https://ultrarag.openbmb.cn/pages/en/getting_started/introduction)
