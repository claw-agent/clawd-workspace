# Bookmark Analysis: 2023822767284490263

## Basic Info
- **Author:** @burkov (BURKOV)
- **URL:** https://x.com/burkov/status/2023822767284490263
- **Date:** Tue Feb 17 18:12:03 +0000 2026
- **Engagement:** 6405 â¤ï¸ | 562 ðŸ” | 209 ðŸ’¬
- **Content Type:** Thread
- **Engagement Score:** 8509

## The Tweet
> LLMs process text from left to right â€” each token can only look back at what came before it, never forward. This means that when you write a long prompt with context at the beginning and a question at the end, the model answers the question having "seen" the context, but the context tokens were generated without any awareness of what question was coming. This asymmetry is a basic structural property of how these models work.

The paper asks what happens if you just send the prompt twice in a row...

## Summary
Burkov shares research showing that simply repeating a prompt twice dramatically improves LLM accuracy â€” because the second pass lets all tokens attend to the full context including the question.

## Deep Analysis
The paper exploits the left-to-right attention asymmetry in LLMs. Context tokens generated before the question never 'see' the question. By repeating the prompt, every token gets a second pass with full bidirectional awareness. Results: accuracy improvements across 7 benchmarks and 7 models (Gemini, ChatGPT, Claude, DeepSeek). One model jumped from 21% to 97% on a name-finding task. No finetuning, no extra output length, minimal latency increase since input processing is parallelized.

## Why This Matters
Immediately actionable prompt engineering technique. Could improve OpenClaw agent accuracy on complex tasks with zero code changes â€” just repeat the prompt. Low effort, potentially high impact.

## Action Items
- [ ] Test prompt repetition technique on OpenClaw tasks
- [ ] Read the full paper
- [ ] Consider implementing as a skill/middleware for complex queries
