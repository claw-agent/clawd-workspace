# Bookmark Analysis: 2017907852120060389

## Basic Info
- **Author:** @0xSero
- **URL:** https://x.com/0xSero/status/2017907852120060389
- **Date:** Sun Feb 01 10:28:17 +0000 2026
- **Engagement:** 1,335 â¤ï¸ | 87 ðŸ” | 33 ðŸ’¬
- **Content Type:** Practical Guide

## The Tweet
> Do you want the best web-scraper out there?
>
> 1. Set Opus as main model
> 2. Set haiku for subagents
> 3. Turn on chrome plugin
> 4. Give it a few search api envs, costs cents
> 5. Prompt it to batch scraping targets to haiku subagents
> 6. Tell it to output JSON responses.
>
> Very good way to find data that's not easily accessible online, they can try programmatic ways, then use the browser if targets not found.

## Summary
Recipe for building a powerful web scraper using Claude Code with Opus as orchestrator and Haiku for parallel scraping subagents. Uses browser fallback when programmatic methods fail.

## Deep Analysis

### The Architecture
1. **Opus as orchestrator** - High reasoning power for planning and coordinating
2. **Haiku for subagents** - Cheap, fast workers for parallel execution
3. **Chrome plugin** - Browser automation for JS-rendered content
4. **Search APIs** - Programmatic approach first (Brave, Google, etc.)
5. **Batch processing** - Distribute targets across subagents
6. **JSON output** - Structured data extraction

### Why This Works
- Cost optimization: Expensive model plans, cheap model executes
- Fallback strategy: API â†’ Browser â†’ Manual approaches
- Parallelization: Many cheap workers > one expensive one
- Structured output: JSON makes downstream processing easier

### Implementation Notes
We already have similar capability:
- browser-use for automation
- web_fetch for simple scraping
- Subagent spawning for parallelization

## Why This Matters
This is exactly the architecture for research/data gathering agents. The Opus/Haiku split is smart cost management.

## Action Items
- [x] Already have similar patterns in place
- [ ] Consider formalizing a "scraper" agent persona
- [ ] Test Opus â†’ Haiku delegation pattern for research tasks
